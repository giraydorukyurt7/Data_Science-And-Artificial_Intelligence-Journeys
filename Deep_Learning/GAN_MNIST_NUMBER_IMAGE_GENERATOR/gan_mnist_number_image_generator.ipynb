{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis with LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0-) IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy             as np\n",
    "import tensorflow        as tf\n",
    "from tqdm                import tqdm\n",
    "\n",
    "from tensorflow.keras.datasets               import mnist\n",
    "from tensorflow.keras.models                 import Sequential\n",
    "from tensorflow.keras.layers                 import LeakyReLU, Dense, Reshape, Conv2D, Flatten, Conv2DTranspose, BatchNormalization\n",
    "from tensorflow.keras.optimizers             import Adam\n",
    "from tensorflow.keras.callbacks              import EarlyStopping\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-) DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train,_), (_,_) = mnist.load_data() #We will only use X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "60000\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Expand dimensions\n",
    "X_train = np.expand_dims(X_train, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "60000\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-) MODELLING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A-) Create discriminator and generator "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a-) Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "    model = Sequential()\n",
    "    #Feature Extraction\n",
    "    model.add(Conv2D(filters    = 64,\n",
    "                     kernel_size= (3,3),\n",
    "                     strides    = 2, # We don't want to reduce data size and loss data.\n",
    "                     padding    = \"same\", \n",
    "                     input_shape = (28,28,1)))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2D(filters    = 128,\n",
    "                     kernel_size= (3,3),\n",
    "                     strides    = 2, # We don't want to reduce data size and loss data.\n",
    "                     padding    = \"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    #Fully Connected Layer\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    #Compile\n",
    "    model.compile(loss=\"binary_crossentropy\",\n",
    "                  optimizer=Adam(learning_rate = 1e-4,\n",
    "                                 beta_1        = 0.5),\n",
    "                  metrics   = [tf.keras.metrics.Precision(name=\"precision\"),\n",
    "                               tf.keras.metrics.Recall(name=\"recall\"),\n",
    "                               tf.keras.metrics.AUC(name=\"auc\"),\n",
    "                               \"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 14, 14, 64)        640       \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 7, 7, 128)         73856     \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 7, 7, 128)         0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 6272)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 6273      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80,769\n",
      "Trainable params: 80,769\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator_model = build_discriminator()\n",
    "discriminator_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b-) Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(7*7*128,#Flatten dimension\n",
    "              input_dim=100)) #From noisy vector transform to high level space\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Reshape((7,7,128)))#transform into matris\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2DTranspose(filters    = 64,\n",
    "                              kernel_size= (3,3),\n",
    "                              strides    = 2, # We don't want to reduce data size and loss data.\n",
    "                              padding    = \"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2DTranspose(filters    = 1,\n",
    "                              kernel_size= (3,3),\n",
    "                              strides    = 2, # We don't want to reduce data size and loss data.\n",
    "                              padding    = \"same\",\n",
    "                              activation = \"tanh\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 6272)              633472    \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 6272)              0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 7, 7, 128)         0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 7, 7, 128)        512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 14, 14, 64)       73792     \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 14, 14, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 28, 28, 1)        577       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 708,609\n",
      "Trainable params: 708,225\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator_model = build_generator()\n",
    "generator_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B-) Create GAN model = discriminator + generator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-) MODEL TESTING"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
